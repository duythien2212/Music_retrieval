{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RkGJ_NPSky59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Information_Retrieval"
      ],
      "metadata": {
        "id": "PqV43YrxF4ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOn72guOFpwi"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/spijkervet/clmr.git && cd clmr\n",
        "%cd ./clmr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "yQ6YSbML7Z9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vào requirement.txt sửa\n",
        "# torch==1.11.0\n",
        "# sklearn thành scikit-learn\n",
        "# pytorch-lightning==1.9.0\n",
        "# !sudo apt install python3-pip\n",
        "!pip install -r requirements.txt\n",
        "# !pip install torch==1.13.0"
      ],
      "metadata": {
        "id": "_Cez6h5OIucP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ],
      "metadata": {
        "id": "baVSMGemlfFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "def preprocessing(input_array):\n",
        "    group_size = 59049\n",
        "\n",
        "    if len(input_array) < group_size:\n",
        "      return torch.unsqueeze(torch.unsqueeze(torch.tensor(input_array), 0))\n",
        "\n",
        "    else:\n",
        "        num_groups = len(input_array) // group_size\n",
        "        current_segment = []\n",
        "\n",
        "        for i in range(num_groups):\n",
        "            start = i * group_size\n",
        "            end = (i + 1) * group_size\n",
        "            audio_segment = torch.from_numpy(input_array[start:end]).reshape(1,-1)\n",
        "            current_segment.append(audio_segment)\n",
        "\n",
        "        if len(input_array) % group_size != 0:\n",
        "            remaining_audio = torch.from_numpy(input_array[num_groups * group_size:])\n",
        "            padded_array = np.pad(remaining_audio, (0, group_size - len(remaining_audio)), 'constant', constant_values=0)\n",
        "            remaining_audio = torch.from_numpy(padded_array).reshape(1,-1)\n",
        "            current_segment.append(remaining_audio)\n",
        "\n",
        "        return torch.stack(current_segment)"
      ],
      "metadata": {
        "id": "qdIKFzMXAYAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(path):\n",
        "  audio, sample_rate = librosa.load(path, sr=22050)\n",
        "  audio = preprocessing(audio)\n",
        "  return audio"
      ],
      "metadata": {
        "id": "GTlpYcS1Hh_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "KY3JAXd08M8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_encoder(checkpoint_path):\n",
        "  n_classes = 50\n",
        "  encoder = SampleCNN(\n",
        "      strides=[3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
        "      supervised=0,\n",
        "      out_dim=n_classes,\n",
        "  )\n",
        "\n",
        "  n_features = encoder.fc.in_features  # get dimensions of last fully-connected layer\n",
        "\n",
        "  state_dict = load_encoder_checkpoint(checkpoint_path, n_classes)\n",
        "  encoder.load_state_dict(state_dict)\n",
        "  encoder.fc = Identity()\n",
        "\n",
        "  return encoder"
      ],
      "metadata": {
        "id": "7CFPAgzv-Noe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_arg(config_path):\n",
        "  parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
        "  parser = Trainer.add_argparse_args(parser)\n",
        "\n",
        "  config = yaml_config_hook(config_path)\n",
        "  for k, v in config.items():\n",
        "      parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
        "\n",
        "  args, unknown = parser.parse_known_args()\n",
        "  pl.seed_everything(args.seed)\n",
        "  args.accelerator = None\n",
        "\n",
        "  if not os.path.exists(args.checkpoint_path):\n",
        "    raise FileNotFoundError(\"That checkpoint does not exist\")\n",
        "  return args"
      ],
      "metadata": {
        "id": "abpWzwgI-tUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchaudio_augmentations import Compose, RandomResizedCrop\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "from clmr.datasets import get_dataset\n",
        "from clmr.data import ContrastiveDataset\n",
        "from clmr.evaluation import evaluate\n",
        "from clmr.models import SampleCNN\n",
        "from clmr.modules import ContrastiveLearning, LinearEvaluation\n",
        "from clmr.utils import (\n",
        "    yaml_config_hook,\n",
        "    load_encoder_checkpoint,\n",
        "    load_finetuner_checkpoint,\n",
        ")\n",
        "\n",
        "def dataset_feature_extraction(dataset_path, output_path):\n",
        "  args = load_arg(\"./config/config.yaml\")\n",
        "\n",
        "  encoder = load_encoder(args.checkpoint_path)\n",
        "  # device = \"cuda:0\" if args.gpus else \"cpu\"\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "      device = torch.device(\"cpu\")\n",
        "  print(\"Running on:\", device)\n",
        "  encoder = encoder.to(device)\n",
        "  encoder.eval()\n",
        "  # print(encoder)\n",
        "\n",
        "  results = []\n",
        "  dataset_files = glob(os.path.join(dataset_path, \"*.mp3\"),\n",
        "      recursive=True)\n",
        "  dataset_files.sort()\n",
        "\n",
        "  index_mapping = {}\n",
        "  index_mapping_path = os.path.join(output_path,'index_mapping.json')\n",
        "  if os.path.exists(index_mapping_path):\n",
        "    with open(index_mapping_path, 'r') as f:\n",
        "      index_mapping = json.load(f)\n",
        "\n",
        "  cnt = len(index_mapping)\n",
        "  for file_path in tqdm(dataset_files):\n",
        "    file_name = file_path.split('/')[-1].split('.')[0]\n",
        "    output_file_path = os.path.join(output_path ,f'{cnt}.pt')\n",
        "\n",
        "    if file_name in index_mapping.keys():\n",
        "      # print(f\"{output_file_path} is already exist\")\n",
        "      continue\n",
        "\n",
        "    index_mapping[file_name] = cnt\n",
        "\n",
        "    audio = load_audio(file_path)\n",
        "    audio = audio.to(device)\n",
        "    with torch.no_grad():\n",
        "      features = encoder(audio)\n",
        "      results.append(features)\n",
        "    torch.save(features, output_file_path)\n",
        "    # print(f\"Saved: {file_name}\")\n",
        "\n",
        "    with open(index_mapping_path, 'w') as f:\n",
        "      json.dump(index_mapping, f, indent=4)\n",
        "    cnt += 1\n",
        "\n",
        "  return index_mapping"
      ],
      "metadata": {
        "id": "ovgfXlqPJi3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_mapping = dataset_feature_extraction(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/dataset/\", \"./test/features/\")"
      ],
      "metadata": {
        "id": "nfTPFKZF8Dvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_mapping)"
      ],
      "metadata": {
        "id": "7s8TRzienO4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from glob import glob\n",
        "\n",
        "# glob(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/dataset/*.mp3\",\n",
        "#     recursive=True,\n",
        "#      )\n",
        "# # print(os.path.join(\n",
        "# #     \"test\", \"**\", \"*{}\".format(\".mp3\")))"
      ],
      "metadata": {
        "id": "c_hifRd1o0FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q52cD43xNs60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query"
      ],
      "metadata": {
        "id": "_6XxDFdaoXj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio"
      ],
      "metadata": {
        "id": "L53SBucQpmnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from glob import glob\n",
        "\n",
        "# mp3_files = glob(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries/**/*.mp3\",\n",
        "#     recursive=True)\n",
        "\n",
        "# mp3_files.sort()\n",
        "# output_folder = \"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries\"\n",
        "\n",
        "# for mp3_file in mp3_files:\n",
        "#   process_audio(mp3_file, output_folder)"
      ],
      "metadata": {
        "id": "NgY4QTHYw9pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index_mapping)"
      ],
      "metadata": {
        "id": "SiVe_GgtxKTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "def get_ground_truth(query_folder):\n",
        "  queries_path = glob(os.path.join(query_folder, \"*.mp3\") ,\n",
        "        recursive=True,\n",
        "      )\n",
        "  queries_path.sort()\n",
        "  print(queries_path)\n",
        "  print(len(queries_path))\n",
        "  queries_name = [path.split(\"/\")[-1] for path in queries_path]\n",
        "  print(queries_name)\n",
        "  file_names = [file_name.split(\".\")[0] for file_name in queries_name]\n",
        "  ground_truth_name = [file_name.split(\" \")[0] for file_name in file_names]\n",
        "  ground_truth = [index_mapping[name] for name in ground_truth_name]\n",
        "  print(ground_truth)\n",
        "  return ground_truth"
      ],
      "metadata": {
        "id": "PdqwotsjoatH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humming_ground_truth = get_ground_truth(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries/humming/\")"
      ],
      "metadata": {
        "id": "UHEg6Z5QAeWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_ground_truth = get_ground_truth(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries/example/\")"
      ],
      "metadata": {
        "id": "_GKw4f6rAgeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(queries_path[3])"
      ],
      "metadata": {
        "id": "wlQ9lZ7D0DRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ground_truth = [102, 102, 102, 103, 55, 55, 55, 55, 99, 103, 102, 103, 103, 103, 103]"
      ],
      "metadata": {
        "id": "OZUYn61axbWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import encode_long\n",
        "def query_feature_extraction(queries_path):\n",
        "  args = load_arg(\"./config/config.yaml\")\n",
        "  encoder = load_encoder(args.checkpoint_path)\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  encoder = encoder.to(device)\n",
        "  encoder.eval()\n",
        "  audio, sample_rate = librosa.load(queries_path, sr=22050)\n",
        "  audio = preprocessing(audio)\n",
        "  audio = audio.to(device)\n",
        "  query_features = encoder(audio)\n",
        "  return query_features\n"
      ],
      "metadata": {
        "id": "-S_6CbBUprs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJpe6874H9Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query_features = query_feature_extraction(queries_path[0])\n",
        "# print(query_features)"
      ],
      "metadata": {
        "id": "dW8k-iX3AwdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search"
      ],
      "metadata": {
        "id": "0XF7H-ZApjFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# query_features = torch.tensor([[1] for i in range(512)])"
      ],
      "metadata": {
        "id": "7_mCyrSqyMtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_features_path = \"./test/features\"\n",
        "\n"
      ],
      "metadata": {
        "id": "W9gHjd73yO-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "def calc_similarity(query_features, audio_features):\n",
        "  ############## Cũ ###############\n",
        "  # sum_similarity = 0\n",
        "  # avg_similarity = 0\n",
        "  # glb_max_similarity = 0\n",
        "\n",
        "  # for query_feature in query_features:\n",
        "  #   max_similarity = 0\n",
        "  #   for dataset_feature in audio_features:\n",
        "  #     cur_similarity = float(torch.cosine_similarity(dataset_feature, query_feature, dim=0))\n",
        "  #     max_similarity = max(max_similarity, cur_similarity)\n",
        "\n",
        "  #     avg_similarity += cur_similarity\n",
        "  #   sum_similarity += float(max_similarity)\n",
        "  #   avg_similarity /= len(audio_features)\n",
        "  #   glb_max_similarity = max(glb_max_similarity, max_similarity)\n",
        "  # return sum_similarity\n",
        "\n",
        "  ######### Mới ##########\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "  # query_features = query_features.to(device)\n",
        "  # audio_features = audio_features.to(device)\n",
        "  similarity = 0\n",
        "  tensor1 = query_features.reshape(1,-1)\n",
        "  query_length = len(query_features)\n",
        "  for i in range(len(audio_features)):\n",
        "    if i + query_length > len(audio_features):\n",
        "      break\n",
        "    cur_similarity = 0\n",
        "    # for k in range(query_length):\n",
        "    #   tensor1 = query_features[k]\n",
        "    #   tensor2 = audio_features[i+k]\n",
        "    #   cur_similarity += float(cosine_similarity(tensor1, tensor2, dim=0))\n",
        "    # cur_similarity /= query_length\n",
        "    tensor2 = torch.tensor(audio_features[i:i+query_length]).reshape(1,-1)\n",
        "    cur_similarity = float(cosine_similarity(\n",
        "                              tensor1,\n",
        "                              tensor2,\n",
        "                              dim=1\n",
        "                            )\n",
        "                          )\n",
        "    similarity = max(similarity, cur_similarity)\n",
        "\n",
        "  return similarity"
      ],
      "metadata": {
        "id": "Gf_9XCe8B--f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieval(query_path, data_features_path):\n",
        "  query_features = query_feature_extraction(query_path)\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "  else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  result = []\n",
        "  for file_name in tqdm(os.listdir(data_features_path)):\n",
        "    if file_name.endswith(\".pt\"):\n",
        "      audio_features = torch.load(os.path.join(data_features_path, file_name), map_location=torch.device(device))\n",
        "      score = calc_similarity(query_features, audio_features)\n",
        "      result.append((score,file_name))\n",
        "  result.sort(reverse=True)\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "P3_JXB0WyetV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# results = []\n",
        "# for i in range(len(queries_path)):\n",
        "#   results.append(retrieval(queries_path[i], data_features_path))"
      ],
      "metadata": {
        "id": "Y1WLx59QPvGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(humming_ground_truth)"
      ],
      "metadata": {
        "id": "1UOXa0ijzDpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(results[9])"
      ],
      "metadata": {
        "id": "vMZ7yoQry-9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: top 1 1 1 1\n",
        "# 1: top 3 5 6 5\n",
        "# 2: top 2 2 1 1\n",
        "# 3: top 1 1 1 1\n",
        "# 4: top 2 2 1 1\n",
        "# 5: top 2 2 1 1"
      ],
      "metadata": {
        "id": "Ks5dJsvr3F4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python preprocess.py --dataset audio --dataset_dir ./test/dataset/\n"
      ],
      "metadata": {
        "id": "OdWb-3GXNvCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python main.py --dataset audio --dataset_dir  ./test/dataset/\n"
      ],
      "metadata": {
        "id": "fuMsBYtTSB8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "ApGltXTQV-Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_precision(retrieval_result):\n",
        "  ap = 0\n",
        "  cnt = 0\n",
        "  for i in range(len(retrieval_result)):\n",
        "    if retrieval_result[i] == 1:\n",
        "      cnt += 1\n",
        "      ap += (cnt / (i + 1))\n",
        "  if cnt == 0:\n",
        "    return ap\n",
        "  return ap/cnt"
      ],
      "metadata": {
        "id": "VKc9NR3YWAMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(average_precision([1,1,0,1,1,0,1,0,0,1]))"
      ],
      "metadata": {
        "id": "XY4-NioJZ6vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(retrieval_results):\n",
        "  map = 0\n",
        "  for retrieval_result in retrieval_results:\n",
        "    map += average_precision(retrieval_result)\n",
        "  return map / len(retrieval_results)"
      ],
      "metadata": {
        "id": "0pGYrgaDYPjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mean_average_precision( [[1,1,0], [1,0,1], [1,1,1]]))"
      ],
      "metadata": {
        "id": "BcqzT6t1YXw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_reciprocal_rank(retrieval_results):\n",
        "  mrr = 0\n",
        "  for retrieval_result in retrieval_results:\n",
        "    for i in range(len(retrieval_result)):\n",
        "      if retrieval_result[i] == 1:\n",
        "        mrr += 1 / (i + 1)\n",
        "        break\n",
        "  return mrr / len(retrieval_results)"
      ],
      "metadata": {
        "id": "WfTIoHar2lSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "%matplotlib inline\n",
        "\n",
        "def draw_precision_recall_curve(retrieval_results):\n",
        "  y_true = np.concatenate(retrieval_results)\n",
        "  y_scores = np.arange(len(y_true), 0, -1)\n",
        "  precision = [0 for i in range(len(retrieval_results[0]))]\n",
        "  recall = [0 for i in range(len(retrieval_results[0]))]\n",
        "  cur_relevant = 0\n",
        "  for j in range(len(retrieval_results[0])):\n",
        "    for i in range(len(retrieval_results)):\n",
        "      if retrieval_results[i][j] == 1:\n",
        "          cur_relevant += 1\n",
        "    precision[j] += cur_relevant/(j+1)/len(retrieval_results)\n",
        "    recall[j] += cur_relevant/len(retrieval_results)\n",
        "  max_precision = 0\n",
        "  for j in reversed(range(len(retrieval_results[0]))):\n",
        "    precision[j] = max(precision[j], max_precision)\n",
        "    max_precision = precision[j]\n",
        "\n",
        "  # print(precision, recall)\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.plot(recall, precision, label=f'PR Curve', color='b', lw=2)\n",
        "  plt.fill_between(recall, precision, alpha=0.2, color='blue', label='Area Under Curve')\n",
        "  plt.xlabel('Recall', fontsize=12)\n",
        "  plt.ylabel('Precision', fontsize=12)\n",
        "  plt.title('Precision-Recall Curve', fontsize=14)\n",
        "  plt.legend(loc='lower left', fontsize=10)\n",
        "  plt.grid(alpha=0.3)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "HegBI35pvXK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_precision_recall_curve(\n",
        "    retrieval_results=[[1,0,0],[0,1,0],[0,1,0]]\n",
        ")"
      ],
      "metadata": {
        "id": "mdu70XefZFKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(query_folder, ground_truth):\n",
        "  queries_path = glob(os.path.join(query_folder, \"**/*.mp3\"),\n",
        "      recursive=True,\n",
        "    )\n",
        "  queries_path.sort()\n",
        "  results = []\n",
        "  for i in range(len(queries_path)):\n",
        "    results.append(retrieval(queries_path[i], data_features_path))\n",
        "\n",
        "  predict_results = [[int(score[1].split('.')[0]) for score in result] for result in results]\n",
        "\n",
        "  isRelevant = [[0 for i in range(len(predict_results[j]))] for j in range(len(predict_results))]\n",
        "  for i in range(len(predict_results)):\n",
        "    for j in range(len(predict_results[i])):\n",
        "      isRelevant[i][j] = 1 if predict_results[i][j] == ground_truth[i] else 0\n",
        "  return mean_average_precision(isRelevant), mean_reciprocal_rank(isRelevant), isRelevant\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d9LBLXF4K9Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humming_mAP, humming_mrr, humming_isRelevant = evaluation(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries/humming\", humming_ground_truth)\n",
        "print(f\"\\nmAP: {humming_mAP}, mrr: {humming_mrr}\")"
      ],
      "metadata": {
        "id": "2PBimGcm__KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_mAP, example_mrr, example_isRelevant = evaluation(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries/example/\", example_ground_truth)\n",
        "print(f\"\\nmAP: {example_mAP}, mrr: {example_mrr}\")"
      ],
      "metadata": {
        "id": "Mp87wxrWA0Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjOzIFfwWC5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MFCC"
      ],
      "metadata": {
        "id": "7HW8qRyASEgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from librosa.sequence import dtw\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function to extract MFCC and pitch features\n",
        "def extract_features(input_array, sr=22050, n_mfcc=20, feature_type=\"mfcc\"):\n",
        "    \"\"\"\n",
        "    Extract MFCC or pitch features from an input audio array.\n",
        "\n",
        "    Args:\n",
        "        input_array (numpy.ndarray): Audio time-series array.\n",
        "        sr (int): Sampling rate of the audio. Default is 22050.\n",
        "        n_mfcc (int): Number of MFCC features to extract (if feature_type=\"mfcc\"). Default is 13.\n",
        "        feature_type (str): Type of feature to extract (\"mfcc\" or \"pitch\"). Default is \"pitch\".\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Extracted features.\n",
        "    \"\"\"\n",
        "    if feature_type == \"mfcc\":\n",
        "        # Extract MFCC features\n",
        "        mfcc = librosa.feature.mfcc(y=input_array, sr=sr, n_mfcc=n_mfcc)\n",
        "        return mfcc.T  # Transpose to get frames as rows\n",
        "    elif feature_type == \"pitch\":\n",
        "        # Extract pitch (using librosa.pyin)\n",
        "\n",
        "        pitch, voiced_flag, _ = librosa.pyin(input_array, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'))\n",
        "        # pitch = np.nan_to_num(pitch)#, nan=0.0)  # Replace NaN values with 0\n",
        "        return pitch#.reshape(-1, 1)  # Reshape to make it 2D\n",
        "    else:\n",
        "        raise ValueError(\"Invalid feature_type. Choose 'mfcc' or 'pitch'.\")\n",
        "\n",
        "# Function to compute Dynamic Time Warping (DTW) distance\n",
        "def perform_dtw(query_features, song_features):\n",
        "    \"\"\"\n",
        "    Compute the matching score between query and song features using DTW.\n",
        "\n",
        "    Args:\n",
        "        query_features (numpy.ndarray): Features of the query (MFCC + pitch).\n",
        "        song_features (numpy.ndarray): Features of the song (MFCC + pitch).\n",
        "\n",
        "    Returns:\n",
        "        float: DTW distance (matching score).\n",
        "    \"\"\"\n",
        "    # Ensure inputs are in the shape (features, time frames)\n",
        "    query_features = query_features.T if query_features.shape[0] > query_features.shape[1] else query_features\n",
        "    song_features = song_features.T if song_features.shape[0] > song_features.shape[1] else song_features\n",
        "    cost_matrix, _ = dtw(query_features, song_features, metric='euclidean')\n",
        "    return cost_matrix[-1, -1]  # Return the final cumulative cost\n"
      ],
      "metadata": {
        "id": "XP1ZCWqbND7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mfcc_dataset_feature_extraction(dataset_path, output_path):\n",
        "  results = []\n",
        "  dataset_files = glob(os.path.join(dataset_path, \"*.mp3\"),\n",
        "      recursive=True)\n",
        "  dataset_files.sort()\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "  index_mapping = {}\n",
        "  index_mapping_path = os.path.join(output_path,'index_mapping.json')\n",
        "  if os.path.exists(index_mapping_path):\n",
        "    with open(index_mapping_path, 'r') as f:\n",
        "      index_mapping = json.load(f)\n",
        "\n",
        "  cnt = len(index_mapping)\n",
        "  for file_path in tqdm(dataset_files):\n",
        "    file_name = file_path.split('/')[-1].split('.')[0]\n",
        "    output_file_path = os.path.join(output_path ,f'{cnt}.npy')\n",
        "\n",
        "    if file_name in index_mapping.keys():\n",
        "      print(f\"{output_file_path} is already exist\")\n",
        "      continue\n",
        "\n",
        "    index_mapping[file_name] = cnt\n",
        "\n",
        "    audio, _ = librosa.load(file_path)\n",
        "    features = extract_features(audio)\n",
        "    results.append(features)\n",
        "\n",
        "    np.save(output_file_path, features)\n",
        "    print(f\"Saved: {file_name}\")\n",
        "\n",
        "    with open(index_mapping_path, 'w') as f:\n",
        "      json.dump(index_mapping, f, indent=4)\n",
        "    cnt += 1\n",
        "\n",
        "  return index_mapping"
      ],
      "metadata": {
        "id": "eOSa5UFrRH42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_index = mfcc_dataset_feature_extraction(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/dataset/\",  \"./test/mfcc_features/\")"
      ],
      "metadata": {
        "id": "6g_msAXITXPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mfcc_retrieval(query_path, data_features_path):\n",
        "  audio, _ = librosa.load(query_path)\n",
        "  query_features =  extract_features(audio)\n",
        "  result = []\n",
        "  for file_name in os.listdir(data_features_path):\n",
        "    if file_name.endswith(\".npy\"):\n",
        "      audio_features = np.load(os.path.join(data_features_path, file_name))\n",
        "      score = perform_dtw(query_features, audio_features)\n",
        "      result.append((score,file_name))\n",
        "  result.sort()\n",
        "  return result\n",
        "\n",
        "mfcc_results = []\n",
        "for i in tqdm(range(len(queries_path))):\n",
        "  mfcc_results.append(mfcc_retrieval(queries_path[i], \"./test/mfcc_features\"))"
      ],
      "metadata": {
        "id": "aSDD0UbnUq3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mfcc_results[0])"
      ],
      "metadata": {
        "id": "60FXuWSiVNSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ground_truth)"
      ],
      "metadata": {
        "id": "sEeT-5mWb26q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_ground_truth = [102, 103, 1, 15, 102]"
      ],
      "metadata": {
        "id": "9Qw3lyG6b49R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mfcc_evaluation(query_folder, ground_truth):\n",
        "  queries_path = glob(os.path.join(query_folder, \"**/*.mp3\"),\n",
        "      recursive=True,\n",
        "    )\n",
        "  queries_path = [queries_path[0], queries_path[2], queries_path[3],queries_path[4], queries_path[5]]\n",
        "  results = []\n",
        "  for i in tqdm(range(len(queries_path))):\n",
        "    results.append(mfcc_retrieval(queries_path[i],  \"./test/mfcc_features\"))\n",
        "  # print(results)\n",
        "  predict_results = [[int(score[1].split('.')[0]) for score in result] for result in results]\n",
        "  # print(predict_results)\n",
        "  isRelevant = [[0 for i in range(len(predict_results[j]))] for j in range(len(predict_results))]\n",
        "  for i in range(len(predict_results)):\n",
        "    for j in range(len(predict_results[i])):\n",
        "      isRelevant[i][j] = 1 if predict_results[i][j] == ground_truth[i] else 0\n",
        "\n",
        "  return mean_average_precision(isRelevant)\n",
        "\n",
        "mfcc_mAP = mfcc_evaluation(\"/content/drive/MyDrive/Information_Retrieval/clmr/test/queries\", mfcc_ground_truth)\n",
        "print(mfcc_mAP)"
      ],
      "metadata": {
        "id": "R9edBsUgVdgV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}